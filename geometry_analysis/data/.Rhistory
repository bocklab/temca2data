t7[3866:3869"3869012"]
t7[3866:3869]
t7[3861:3869]
source('~/myscripts/bocklab_git/bocklab/zhihao/r/scripts/170927-compute_active_bouts.R', echo=TRUE)
t1 = get_ped(kc_v13, "indices")
t1 = get_ped(kc_v13[[1]], "indices")
t1 = get_ped(kc_v13[[2]], "indices")
ped_n = subset(n, get_ped(n, "indices"))
kc_v13_ped[[i]] = ped_n
rp = subset_nodes(response_v13[[i]], get_ped(n))
results[[i]] = get_time(ped_n, rp, n$skid)
is.neuron(ped_n)
n$skid
n = ped_n
skid=282181
tt = sapply(rp[[1]], function(x) c(x[[9]], x[[10]])) %>% get_aggregated_time
tt = sapply(rp[[1]], function(x) c(x[[9]], x[[10]]))
tt[1:3]
install.packages("circlize", lib="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library(circlize)
circos.link(sector.index1, 0, sector.index2, 0)
factors = letters[1:8]
circos.par(points.overflow.warning = FALSE)
circos.initialize(factors = factors, xlim = c(0, 10))
circos.track(factors = factors, ylim = c(0, 1), bg.col = "grey",
bg.border = NA, track.height = 0.05)
circos.link("a", 5, "c", 5, border = 1)
circos.link("b", 5, "d", c(4, 6), border = 1)
circos.link("a", c(2, 3), "f", c(4, 6), border = 1)
circos.link("e", c(2, 3), "g", 5, border = 1)
factors
factors = letters[1:8]
circos.par(points.overflow.warning = FALSE)
circos.initialize(factors = factors, xlim = c(0, 10))
circos.track(factors = factors, ylim = c(0, 1), bg.col = "grey",
bg.border = NA, track.height = 0.05)
circos.link("a", 5, "c", 5, border = 1)
circos.link("b", 5, "d", c(4, 6), border = 1)
circos.link("e", c(2, 3), "g", 5, border = 1)
?chordDiagram
library(nat.nblast)
?nblast
db_fpath = '/Volumes/bock/old_homes/bocklab/people/Zhihao/db/170703_mz19_project_random_model'
db = dbConnect(SQLite(), db_fpath)
summary_100kc = dbReadTable(db, "pre_connected_100kc_summary_170703")
library(xlsx)
library(dplyr)
library(magrittr)
library(pwr)
library(RSQLite)
library(ggplot2)
db_fpath = '/Volumes/bock/old_homes/bocklab/people/Zhihao/db/170703_mz19_project_random_model'
db = dbConnect(SQLite(), db_fpath)
summary_100kc = dbReadTable(db, "pre_connected_100kc_summary_170703")
db_fpath = '/Volumes/bock/old_homes/bocklab/people/Zhihao/db/170703_mz19_project_random_model'
db = dbConnect(SQLite(), db_fpath)
db_fpath = '/Volumes/bock/old_homes/bocklab/people/Zhihao/db/170703_mz19_project_random_model'
db = dbConnect(SQLite(), db_fpath)
summary_100kc = dbReadTable(db, "pre_connected_100kc_summary_170703")
summary_100kc
write.xlsx(summary_100kc, "170703_simulatedKC_data.xlsx")
library(dplyr)
library(RSQLite)
library(reshape2)
library(ggplot2)
db_fpath = '/Volumes/bock/old_homes/bocklab/people/Zhihao/db/170905_fafb_smoothing'
db = dbConnect(SQLite(), db_fpath)
db_list_tables(db)
dbListTables(DB)
dbListTables(db)
su = '~/myscripts/credentials/catmaid_fafb_login_v13.R'
source(su)
load("~/myscripts/git_clone/bocklab_public/temca2data/geometry_analysis/data/multiverse_v13.RData")
p.nhop = 2;    # how many nodes away from central node to consider during rescop procedure.
p.close_thresh = 800; # How close counts as close for nodes
p.rs_dist = 80
library(catmaid)
library(nat)
library(dplyr)
library(ggplot2)
library(mushroom)
get_votes <- function(dn, qn, close_thresh=p.close_thresh) {
require(igraph)
nn_dist = nabor::knn(data=xyzmatrix(dn), query=xyzmatrix(qn), k=1)
ng = as.ngraph(qn)
t1 = dfs(ng, root=which(qn$d$Parent == -1), neimode='out', unreachable=FALSE)$order
counter = c()
votes = c()
for (j in t1) {
t2 = ego(ng, mode = "all", nodes = t1[[j]])
t_thresh = nn_dist$nn.dists[unlist(t2)] < close_thresh
counter[[j]] = t_thresh %>% any %>% as.numeric
votes[[j]] = t_thresh %>% all %>% as.numeric
}
list('counter'=counter, 'votes'=votes)
}
get_catmaid_link <- function(xyz) {
sprintf('https://neuropil.janelia.org/tracing/fafb/v13/?pid=1&xp=%s&yp=%s&zp=%s&tool=tracingtool&sid0=5&s0=1',
xyz[[1]], xyz[[2]], xyz[[3]])
}
get_fragment_parents <- function(n, subset_points) {
# for example, subset_points = !(counter %>% as.logical)
n_diff = subset(n, subset_points)
n_diff$d[which(n_diff$d$Parent == -1),'PointNo']
}
# put together a table of team names, CATMAID links
results = c()
for (i in seq_along(nl)) {
n_diff = subset(gl, !(discrp[[i]]$counter %>% as.logical))
xyzd = n_diff$d[which(n_diff$d$Parent == -1), c("X","Y","Z")]
t1 = c()
for (row in 1:nrow(xyzd)) {
t1[[row]] = get_catmaid_link(xyzd[row,])
}
results[[i]] = data.frame(t1) %>% setNames("link") %>% mutate("skid"=names(nl)[[i]])
}
path_between <- function(n, starts, ends) {
t1 = get_tagged_node(n, starts, "indices")
t2 = get_tagged_node(n, ends, "indices")
shortest_paths(as.ngraph(n), from = t1, to = t2, mode='all', output = "vpath")
}
discrp = lapply(nl, get_votes, gl)
data_tbl = bind_rows(results)
results = list()
lens = list()
for (i in seq_along(nl)) {
n_diff = subset(gl, !(discrp[[i]]$counter %>% as.logical))
n_comp = n_diff %>% as.ngraph %>% components
frag_list = c()
len_c = c()
for (j in 1:n_comp$no) {
t1 = n_diff$d[which(n_comp$membership == j),'PointNo']
frag_list[[j]] = t1
len_c[[j]] = subset(gl, t1) %>% summary %>% .$cable.length
}
lens[[i]] = len_c
results[[i]] = frag_list
#  points3d(gl$d[t11, c("X","Y","Z")], color = 'black', size=5)
}
get_len <- function(n) summary(n)$cable.length
# for 1st team neuron (skid - 5115189, name - "neuron 5115190")
# first 2 fragments should be combined:
# 1701 - 721649.6 212770.8 160677.4
# (1) 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723
# 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746
# 1747 1748 1749
# 1759 - 721650.5 212709.7 160894.1
# (2) 1759 1760 1761 1762
all_lens = lens
t1 = all_lens[[1]]
t1[[1]] = sum(t1[1:2])
t1 = t1[-c(2)]
all_lens[[1]] = t1
code_dir
setwd(code_dir)
allpndps=flycircuit::load_si_data('allpndps.rds')
pns = allpndps[!sapply(attr(allpndps, 'df')$glom, is.na)]
options(nat.default.neuronlist='pns')
len = 10
# general packages
library(magrittr)
library(rgl)
library(dplyr)
# neuro
library(catmaid)
library(elmr)
library(nat)
library(nat.flybrains)
library(mushroom)
library(flycircuit)
library(reshape2)
doMC::registerDoMC(7)
?flycircuit
?nblast
?nblast
?nblast
pns
length(pns)
names(pns)
names(pns[[1]])
attr(pns[1])
attr(pns[1],'name')
names(pns[1])
attributes(pns[1])
attributes(pns[1], 'df')
attr(pns[1], 'df')
t2= attr(pns[1], 'df')
t2$glom
t2= attr(pns, 'df')$glom
t2
t2= attr(pns, 'df')$glom %>% unique
t2
t2= attr(pns, 'df')$glom %>% unique %>% sort %>% print
?nblast
da1 = subset(pns, glom=="DA1")
length(da1)
?nblast
da1_results = nblast(da1)
da1_results
1
1
da1_results = nblast(da1, normalised = TRUE)
dim(da1_results)
head(da1_results)
View(da1_results)
length(da1)
dim(da1)
dim(da1_results)
?max
?apply
apply(da1_results, 1, max)
t5 = apply(da1_results, 1, max)
dim(t5)
length(t5)
t5 = apply(da1_results, 2, max)
t5
sort(da1_results[,1])
sort(da1_results[,1], decreasing = TRUE)
sort(da1_results[,1], decreasing = TRUE)[1:5]
t5 = subset(pns, glom %in% c("DA1","DA2"))
length(t5)
t5 = subset(pns, glom %in% gloms)
gloms = c("D doublet", "DA1", "DA2",
"DA4",  "DC2",
"DC3", "DL1", "DL2d",
"DL2v", "DL3", "DL4",
"DM1", "DM5",
"DM6", "DP1l", "DP1m",
"V", "VA1d", "VA1v",
"VA4", "VA7m", "VC2",
"VC3l", "VC3m", "VC4",
"VM1", "VM2", "VM3", "VM4",
"VM5d", "VM5v", "VM6",
"VM7")
t5 = subset(pns, glom %in% gloms)
t5 = subset(pns, glom %in% c("DA1","DA2")) %>% nblast(normalise=TRUE)
dim(t5)
t6 = lapply(t5, function(x) sort(x, descreasing=TRUE)[1:2])
t6 = lapply(t5, function(x) sort(x, decreasing=TRUE)[1:2])
t6
t6 = apply(t5, 2, function(x) sort(x, decreasing=TRUE)[1:2])
t6
gloms = c("D doublet", "DA1", "DA2",
"DA4",  "DC2",
"DC3", "DL1", "DL2d",
"DL2v", "DL3", "DL4",
"DM1", "DM5",
"DM6", "DP1l", "DP1m",
"V", "VA1d", "VA1v",
"VA4", "VA7m", "VC2",
"VC3l", "VC3m", "VC4",
"VM1", "VM2", "VM3", "VM4",
"VM5d", "VM5v", "VM6",
"VM7")
results = list()
for (a_glom in gloms) {
results[a_glom] = subset(pns, glom==a_glom) %>%
nblast(normalise=TRUE) %>%
apply(2, function(x) sort(x, decreasing=TRUE)[2:5])
}
warnings()
a_glom = "DA1"
T6 =
subset(pns, glom==a_glom) %>%
nblast(normalise=TRUE) %>%
apply(2, function(x) sort(x, decreasing=TRUE)[2:5])
t6 = subset(pns, glom==a_glom) %>%
nblast(normalise=TRUE) %>%
apply(2, function(x) sort(x, decreasing=TRUE)[2:5])
t6 = subset(pns, glom==a_glom) %>% as.neuronlist %>%
nblast(normalise=TRUE) %>%
apply(2, function(x) sort(x, decreasing=TRUE)[2:5])
results = list()
for (a_glom in gloms) {
results[a_glom] = subset(pns, glom==a_glom) %>%
as.neuronlist()
nblast(normalise=TRUE) %>%
apply(2, function(x) sort(x, decreasing=TRUE)[2:5])
}
results = list()
for (a_glom in gloms) {
results[a_glom] = subset(pns, glom==a_glom) %>%
as.neuronlist %>%
nblast(normalise=TRUE) %>%
apply(2, function(x) sort(x, decreasing=TRUE)[2:5])
}
warnings()
?warning
warn
?tryCatch
results = list()
for (a_glom in gloms[1:10]) {
results[a_glom] = subset(pns, glom==a_glom) %>%
as.neuronlist %>%
nblast(normalise=TRUE) %>%
apply(2, function(x) sort(x, decreasing=TRUE)[2:5])
}
results = list()
for (a_glom in gloms[1:10]) {
tryCatch({
results[a_glom] = subset(pns, glom==a_glom) %>%
as.neuronlist %>%
nblast(normalise=TRUE) %>%
apply(2, function(x) sort(x, decreasing=TRUE)[2:5])
},
warning = function(w) {
print(a_glom)}
)
}
results[[1]]
results[[]
]
results[1]
results[['DA1']]
results
results = list()
for (a_glom in gloms[1:10]) {
tryCatch({
results[[a_glom]] = subset(pns, glom==a_glom) %>%
as.neuronlist %>%
nblast(normalise=TRUE) %>%
apply(2, function(x) sort(x, decreasing=TRUE)[2:5])
},
warning = function(w) {
print(a_glom)}
)
}
results
length(results)
results[[1
]]
names(results[1])
names(results[2])
results[[2]]
dim(results[[2]])
unlist(results[[2]])
t6 = unlist(results[[2]])
t6
dim(t6)
dim(results[[2]])
as.vector(results[[2]])
results = list()
for (a_glom in gloms) {
tryCatch({
results[[a_glom]] = subset(pns, glom==a_glom) %>%
as.neuronlist %>%
nblast(normalise=TRUE) %>%
apply(2, function(x) sort(x, decreasing=TRUE)[2:5])
},
warning = function(w) {
print(a_glom)}
)
}
lapply(results, length)
t8=lapply(results, as.vector %>% max)
t8=lapply(results, function(x) as.vector(x) %>% max)
t8
length(t8)
length(gloms)
gloms = c("D doublet", "DA1", "DA2",
"DA4",  "DC2",
"DC3", "DL1", "DL2d",
"DL2v", "DL3", "DL4",
"DM1", "DM5",
"DM6", "DP1l", "DP1m",
"V", "VA1d", "VA1v",
"VA4", "VA7m", "VC2",
"VC3l", "VC3m", "VC4",
"VM1", "VM2", "VM3", "VM4",
"VM5d", "VM5v", "VM6",
"VM7")
results = list()
for (a_glom in gloms) {
tryCatch({
results[[a_glom]] = subset(pns, glom==a_glom) %>%
nblast(normalise=TRUE) %>%
apply(2, function(x) sort(x, decreasing=TRUE)[2:5])
},
warning = function(w) {
print(a_glom)},
error = function(e) {
print(a_glom)
}
)
}
t8=lapply(results, function(x) as.vector(x) %>% c(max,min))
t8
t8=lapply(results, function(x) as.vector(x) %>% max)
t8
length(t8)
median(t4$delta, na.rm=TRUE)
t3
?median
load("~/myscripts/git_clone/bocklab_public/temca2data/geometry_analysis/data/neurons_for_jitters.RData")
length(kc_nl)
library(dplyr)
library(RSQLite)
library(reshape2)
library(ggplot2)
library(catmaid)
get_displacements <- function(n, n_sm) {
nx = xyzmatrix(n)
nsx = xyzmatrix(n_sm)
r = sapply(seq_len(nrow(nx)), function(x) sqrt(sum((nx[x,] - nsx[x,])^2)))
data.frame(r, n$d$Z/35) %>% setNames(c("distance","section_num"))
}
smooth_nl <- function(nl) nlapply(nl, smooth_neuron, method = "gauss", sigma=12000)
# kc_nl = read.neurons.catmaid("annotation:^fafb_ms_KCs$", conn=fafb_conn)
# apl_nl = read.neurons.catmaid(203840, conn=fafb_conn)
# pn_nl = read.neurons.catmaid("annotation:^fafb_ms_PNs$", conn=fafb_conn)
kc_sm_nl = nlapply(kc_nl, smooth_neuron, method = "gauss", sigma=12000)
apl_sm_nl = nlapply(apl_nl, smooth_neuron, method = "gauss", sigma=12000)
pn_sm_nl = nlapply(pn_nl, smooth_neuron, method = "gauss", sigma=12000)
# start processing neuronlist (nl)
# nl = kc_nl
# nl = apl_nl
nl = c(pn_nl, apl_nl, kc_nl)
nl_sm = smooth_nl(nl)
results = lapply(seq_along(nl), function(x) get_displacements(nl[[x]], nl_sm[[x]]))
# get the means of each section---------
data_tbl2 = bind_rows(results) %>%
group_by(section_num) %>%
summarise(dist_mean=mean(distance))
t1 = data_tbl2$dist_mean
t2 = abs(t1[2:length(t1)] - t1[1:(length(t1)-1)]) / 1e3
t3 = cbind(t2, data_tbl2$section_num[2:length(t1)]) %>% data.frame %>% setNames(c("delta","section_num"))
t4 = seq_len(7062) %>% setdiff(t3$section_num %>% unique) %>% data.frame %>% setNames("section_num") %>% full_join(t3)
median(t4$delta, na.rm=TRUE)
max(t4$delta)
?max
max(t4$delta, na.rm=TRUE)
library(nat)
?smooth_neuron
load("/Users/zhengz11/myscripts/data_results/170331-EMvsLM_calyx_tightness_Fig5_FAFB2017/lm_coll_subset_170331.rda")
names(lm_subset_170331)
lm_subset_170331[[1]]
names(lm_subset_170331[1])
library(nat.flybrains)
?JFRC2013
?hclust
?t.test
?hclust
?bb
library(nat)
?boundingbox
library(nat.nblast)
??hclust
?nclass.FD
?hclust
load("~/myscripts/git_clone/bocklab_public/temca2data/geometry_analysis/data/fc_pns0219.rda")
plot(fc_pns0219)
load("~/myscripts/git_clone/bocklab_public/temca2data/geometry_analysis/data/pns.RData")
plot3d(pns)
?nblast
?nhclust
?sub_dist_mat
?dist
?distfun
?sub_dist_mat
?as.dist
?sub_dist_mat
?sub_score_mat
?as.dist
?nhclust
?nhclust
?hclust
138474.2 / 35
require(catmaid)
fafb_conn=catmaid_login(server="https://neuropil.janelia.org/tracing/fafb/v14/", token="9583bd368fbac3f65aaaf8a2d32ed179c8de9d9d")
?read.neurons.catmaid
kcs = read.neurons.catmaid("annotation:^Complete$")
library(elmr)
FAFB13NP.suRF
FAFB13NP.surf
FAFB14NP.surf
devtools::update_packages("elmr", dependencies = TRUE)
library(elmr)
rm(kcs)
remove.packages("rgl", lib="~/Library/R/3.3/library")
install.packages("rgl", lib="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
devtools::update_packages("elmr", dependencies = TRUE)
library(elmr)
library("elmr", lib.loc="~/Library/R/3.3/library")
detach("package:elmr", unload=TRUE)
remove.packages("elmr", lib="~/Library/R/3.3/library")
devtools::install_github("jefferis/elmr", dependencies=TRUE)
library(elmr)
load("~/myscripts/git_clone/bocklab_public/temca2data/geometry_analysis/data/multiverse_v13.RData")
library(nat.nblast)
?NeuriteBlast
load("~/myscripts/git_clone/temca2data/geometry_analysis/data/pns.RData")
pns[,]
library(nat)
pns[,]
attributes(pns)
uPN = subset(pns, glomerulus != "olfactory_multi_glom_PN")
length(uPN)
uPN[,]
uPN[110,'glomerulus']
uPN[110,'glomerulus'] == "olfactory_multi_glom_PN"
uPN[109,'glomerulus'] == "olfactory_multi_glom_PN"
pns[,]
attributes(pns)
class(pns)
pns[,]
as.neuronlist(pns)
as.neuronlist(pns)[,]
as.neuronlist(pns) %>% as.data.frame()
as.neuronlist(pns) %>% as.data.frame
setwd("/Users/zhengz11/myscripts/git_clone/temca2data/geometry_analysis/data")
load("~/myscripts/git_clone/temca2data/geometry_analysis/data/fb_gj_ca_skln_170403.rda")
load("~/myscripts/git_clone/temca2data/geometry_analysis/data/fb_gj_ca_skln_170403.rda")
